{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "06ee1884",
   "metadata": {},
   "source": [
    "**By :**\n",
    "Zamzam Alsarayrah"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa3726ed",
   "metadata": {},
   "source": [
    "# Chest X-Ray with 5 class"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae0aabae",
   "metadata": {},
   "source": [
    "> # Contents\n",
    "\n",
    "- [Problem Statement](#problem-statement)\n",
    "- [Data Collection](#Data-Collection)\n",
    "- [Observations from EDA](#observations-from-eda)\n",
    "- [Modeling Methodology](#modeling-methodology)\n",
    "- [Requirements](#Requirements)\n",
    "- [Results](#results)\n",
    "- [Conclusions](#conclusions)\n",
    "- [References](#references)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ee514da",
   "metadata": {},
   "source": [
    "> ## Problem statement:\n",
    "\n",
    "**The global pandemic of coronavirus disease 2019 (COVID-19) has resulted in an increased demand for testing, diagnosis, and treatment. So the chest X-ray radiography (CXR) is a fast, effective, and affordable test that identifies the possible COVID-19-related pneumonia. We are going to check if we can diagnose the chest disease based on the X_RAY by using machine learning method.One main goal is the covid-19, we are going to test different machine learning models and their ability to diagnose the covid-19 chest-ray among other 4 different chest diseases.**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b011f174",
   "metadata": {},
   "source": [
    "**[Back to Top](#Contents)**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2731cfd",
   "metadata": {},
   "source": [
    "> ## Data Collection\n",
    "\n",
    "Source: [Dataverse.harvard](https://dataverse.harvard.edu/file.xhtml?fileId=5210381&version=5.0)\n",
    "\n",
    "The dataset is organized into 3 folders:\n",
    "1. Train 19610 (60%) \n",
    "2. Test  6540  (20%)\n",
    "3. Validation 6534  (20%)\n",
    "\n",
    "and contains subfolders for each image category:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8effb88f",
   "metadata": {},
   "source": [
    "| Clasess Name | Count |\n",
    "| ----------- | ----------- |\n",
    "| Normal  | 10,192 |\n",
    "| COVID-19 | 4,189 |\n",
    "| Tuberculosis | 4,897 |\n",
    "| Lung-Opacity | 6,012 |\n",
    "| Viral Pneumonia | 7,397 |\n",
    "| **Total** | 32,687 |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c814c1e",
   "metadata": {},
   "source": [
    "### Test \n",
    "![Test Images](./assets/test-images.png)\n",
    "### Train\n",
    "![Train Images](./assets/train-images.png)\n",
    "### Validation\n",
    "![val Images](./assets/val-images.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "330b32e8",
   "metadata": {},
   "source": [
    "**[Back to Top](#Contents)**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03a1403c",
   "metadata": {},
   "source": [
    "![](images/image.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a06617a",
   "metadata": {},
   "source": [
    "> ## Observations from EDA ([Demo notebook_EDA](/notebooks/project/project-capstone/X_ray/chest_x-ray/Load%20the%20Data%20and%20EDA.ipynb))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8fbb8bf",
   "metadata": {},
   "source": [
    "**Class Dictionary** \n",
    "\n",
    "| Class Name | Label |\n",
    "| ----------- | ----------- |\n",
    "| COVID-19 | 0 |\n",
    "| Lung-Opacity | 1 |\n",
    "| Normal | 2 |\n",
    "| Viral Pneumonia | 3 |\n",
    "| Tuberculosis | 4 |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83269720",
   "metadata": {},
   "source": [
    "- The dataset contains colored images with three channels RGB.\n",
    "- All the images has the same sizes (224*224) we don’t need to resize the images.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2cf6783",
   "metadata": {},
   "source": [
    "### The distribution of the classes in the train, test and validation data\n",
    "![class distribution](./assets/class_distribution.png)\n",
    "\n",
    "**We can see that the data has the same distribution among the different classes in all the dataset(train, test and validation)\n",
    "The classes that has the most number of images is the normal classes where the one with the least number of images is COVID-19\n",
    "This is expected situation as the other disease has long history where COVID-19 is a new disease, so there is no much data as the other classes.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bed85d53",
   "metadata": {},
   "source": [
    "**[Back to Top](#Contents)**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "451d68b6",
   "metadata": {},
   "source": [
    "> # Modeling Methodology ([Demo notebook_code](/notebooks/project/project-capstone/X_ray/chest_x-ray/notebook.ipynb))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8543fd6",
   "metadata": {},
   "source": [
    "**Train, test and validation split :**\n",
    "\n",
    "The data set is already splitter to train, test and validation. We don’t have to do any thing with the splitting. The train and test images are used to train and validate the model during the training process where the validation images will be used to test the different models accuracy after the train.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59356976",
   "metadata": {},
   "source": [
    "- ### Base Model Architecture: \n",
    "Custom CNN Model This model has 2 Convolutional (Conv) (Conv2D + MaxPooling2D) layers, followed by 2 Fully Connected (FC) layers and a final SoftMax activation layer for classification. All layers use ReLU activation except where mentioned.\n",
    "- ### Transfer learning via feature extraction:\n",
    "We used two different techniques for feature extraction. One using PCA and the other using pre-trained CNN (VGG16). We input the images to the feature extractor, the output is the features of each image, then these feature used as an input to a classification technique to classify the image.\n",
    "- **PCA (Principle component analysis): \n",
    "It is a dimensionally reduction technique where it does a feature extraction to the input data. In feature extraction the  existing features are combined together in a particular way, then some of these \"new\" variables are dropped, but the variables we keep are still a combination of the old variables. \n",
    "This allows us to still reduce the number of features in our model but we can keep all of the most important pieces of the original features.In our project we used 1000 component, the original features were 224*224 features for each image for each color, using the PCA with 1000 components, these huge number of features were reduced to 3000 features (1000 feature for each color).**\n",
    "- ### VGG16 Model Architecture:\n",
    "VGG16 is a pre-trained CNN network by Simonyan and Zisserman. It used as a classifier or features extractor. When using it as a feature extractor we chop “chop off” the network at a specified layer which is mainly prior to the fully-connected layers. The output of the VGG16 extractor will be  7 x 7 x 512 = 25,088 features, which is the shape of the final max-pooling layer of the chopped VGG16. These extracted features will be fed into other classifier to classify the image.\n",
    "- ### Classification Models:\n",
    "Classification using logistic regression and random forest models with multi class output. We used Random-search with both model to help with tuning the hyperparamters. We fed these models with the extracted features from the PCA and the VGG16."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "974d4a06",
   "metadata": {},
   "source": [
    "**[Back to Top](#Contents)**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b59d4a77",
   "metadata": {},
   "source": [
    "># Requirements"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47517cae",
   "metadata": {},
   "source": [
    "**The main requirements are listed below:**\n",
    "- Python 3.6\n",
    "- Numpy\n",
    "- Tensorflow , keras\n",
    "- OpenCV 4.2.0\n",
    "- Scikit-Learn\n",
    "- Matplotlib\n",
    "\n",
    "**Additional requirements to generate dataset:**\n",
    "- Pandas\n",
    "- Jupyter\n",
    "- Google colab"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11fb7c3f",
   "metadata": {},
   "source": [
    "**[Back to Top](#Contents)**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a788550",
   "metadata": {},
   "source": [
    "| Model name | Train Score | Test Score |\n",
    "| ----------- | ----------- |----------- |\n",
    "| logistic_pca  | 0.74 |0.68 |\n",
    "| logistic_vgg | 1.0 |0.91 |\n",
    "| RFC_pca | 0.99 |0.58 |\n",
    "| RFC_vgg | 0.99 |0.76 |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f2d4c54",
   "metadata": {},
   "source": [
    "># Results:\n",
    "\n",
    "\n",
    "From the table above witch shows the train and test accuracy for the different models we have applied, we can see that all of them has an overfit. The one with the best performance among them is the vgg16 with logistic regression, it has a 1 train accuracy and 0.91 test accuracy. If we would pick one model from the above model we will pick the vgg16 with logistic regression. We can notice that the PCA for feature extraction and then apply simple classification models didn’t work well. Even though the features extracted using the PCA covers almost more than 90% of the variance on the images, it didn’t do well in the classification. The base model we have did good work compare to the other models."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8f266c4",
   "metadata": {},
   "source": [
    "**[Back to Top](#Contents)**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b55793c",
   "metadata": {},
   "source": [
    "># Conclusion :\n",
    "\n",
    " \n",
    "The features extracted by the PCA can’t do well with the classification\n",
    "VGG feature extractor did well but still has overfit\n",
    "For our problem and data, logistic regression is better than random forest classifier\n",
    "The base model did well and model with PCA features extractor could not get performance better than the base model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77b03572",
   "metadata": {},
   "source": [
    "**[Back to Top](#Contents)**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cc1e1b8",
   "metadata": {},
   "source": [
    "># Recommendation:\n",
    "\n",
    " \n",
    "\n",
    "- Do More error analysis such that the precision and recall and check what class did confused with the COVID-19 more to work more on this class.\n",
    "- Try to get the human level error (the percentage of error that the doctor can do while classify these x-ray) and compare it with the best model we have to work more on it.\n",
    "- Try to get more data for the test so the model will have more data to test on and improve its performance.\n",
    "- Use NN after the VGG feature extractor with overfitting solution such as drop out and regularization\n",
    "- Do some images augmentation to increase the train and test data\n",
    "- Use more powerful computer with better storage to be able to run the model faster as we are working with images data witch has large size."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c426cf5f",
   "metadata": {},
   "source": [
    "># References\n",
    "\n",
    "[1] [kaggle_COVID-19 Radiography Database](https://www.kaggle.com/tawsifurrahman/covid19-radiography-database)\n",
    "\n",
    "[2] [github](https://github.com/agchung/Actualmed-COVID-chestxray-datase)\n",
    "\n",
    "[3] [github_COVID-19 Chest X-ray Dataset ](https://github.com/agchung/Figure1-COVID-chestxray-dataset)\n",
    "\n",
    "[4] [kaggle_RSNA Pneumonia Detection Challenge](https://www.kaggle.com/c/rsna-pneumonia-detection-challenge/data)\n",
    "\n",
    "[5] [kaggle_Tuberculosis (TB) Chest X-ray Database](https://www.kaggle.com/tawsifurrahman/tuberculosis-tb-chest-xray-dataset)\n",
    "\n",
    "[6] [kaggle_Tuberculosis Chest X-rays](https://www.kaggle.com/raddar/tuberculosis-chest-xrays-shenzhen)\n",
    "\n",
    "[7] [openi](https://openi.nlm.nih.gov/faq#collection)\n",
    "\n",
    "[8] [radiologymasterclass](https://www.radiologymasterclass.co.uk)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d77f73b",
   "metadata": {},
   "source": [
    "**[Back to Top](#Contents)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "060ce8e6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
